{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a-c)   #개선\n",
    "    sum_exp_a = sum(np.exp(a-c))\n",
    "    y = exp_a/sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 ONE-HOT 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        np.random.seed(5) #항상 동일한 랜덤값 출력을 위함 (수업 목적)\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화 (정규분포 : 평균이 0이고 표준편차가 1인 분포값)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t): #입력을 받아서 정답과 얼마나 차이가 나는지 보기(error)\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2X3형태의 형상을 갖는 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/NN.png' width=200px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = simpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.6, 0.9]) # 입력\n",
    "t = np.array([0, 0, 1]) #정답, TARGET, 정답의 확률(3개 더했을 때 총 합이 1이 나와야 함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2개의 입력값($x_1$, $x_2$)과 3개의 정답($y_1$, $y_2$, $y_3$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44122749, -0.33087015,  2.43077119],\n",
       "       [-0.25209213,  0.10960984,  1.58248112]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W #어떤값으로 초기화 되어있는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력값을 이용하여 FORWARD 방향 연산해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03785358 -0.09987323  2.88269572]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = softmax(pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05243789 0.04569106 0.90187105]\n"
     ]
    }
   ],
   "source": [
    "print(y) # 확률로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y) # y중에 값을 가장 크게 하는 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(t) # 정답"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동일한 입력값과 정답을 이용하여 loss 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10328361502771058"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.loss(x,t) # 입력 x를 넣고, target인 t를 넣으면 loss는 0.1이 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greadient 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient_single_point(f, x, verbose=False): \n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    if verbose:\n",
    "        print('x.size={}'.format(x.size)) # (x0, x1) 을 입력으로 받음 --> 2\n",
    "       \n",
    "    for idx in range(x.size): #축별로 계산\n",
    "        v_keep = x[idx]\n",
    "        \n",
    "        # f(x+h) 계산\n",
    "        x[idx] = float(v_keep) + h #n차원 입력 중 해당 차원으로만 h를 더하고\n",
    "        fxh1 = f(x)\n",
    "        if verbose:\n",
    "            print(x, '-->', fxh1)\n",
    "        \n",
    "        # f(x-h) 계산\n",
    "        x[idx] = float(v_keep) - h #n차원 입력 중 해당 차원으로만 h를 빼서\n",
    "        fxh2 = f(x)\n",
    "        if verbose:\n",
    "            print(x, '-->', fxh2)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h) #n차원 방향의 차분을 구함 !\n",
    "        x[idx] = v_keep # 값 복원\n",
    "        \n",
    "        if verbose:\n",
    "            print('grad[{}]={}'.format(idx, grad[idx]))\n",
    "            print()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, X):\n",
    "    if X.ndim == 1:\n",
    "        return numerical_gradient_single_point(f, X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        \n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = numerical_gradient_single_point(f, x)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44122749, -0.33087015,  2.43077119],\n",
       "       [-0.25209213,  0.10960984,  1.58248112]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고) lambda <br>\n",
    "&emsp;&emsp;lambda 인자리스트: 표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w): #Loss 산의 높이\n",
    "    return net.loss(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위처럼 해도 되지만, 아래처럼 lambda 를 써서 간단히 하는 것도 좋은 방법. 단, 인자로 들어가는 w는 dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda w: net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW = numerical_gradient(f, net.W) # 6 방향의 기울기 (6개의 방향의 기울기를 구할 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03146273  0.02741463 -0.05887736]\n",
      " [ 0.0471941   0.04112195 -0.08831604]]\n"
     ]
    }
   ],
   "source": [
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44122749, -0.33087015,  2.43077119],\n",
       "       [-0.25209213,  0.10960984,  1.58248112]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생각해보기\n",
    "* 각 숫자들의 의미를 생각해보세요 (2020/11/24일 수업) <br>\n",
    "    : net.W에서 하나의 값을 변동시키면 loss(에러)가 dW값 만큼 줄어든다. <br>\n",
    "    : 예를 들어 net.W의 (1,1)에 있는 0.44의 값을 변동시키면 loss는 dW에서 net.W와 같은 위치에 있는 값인 0.03배만큼 늘어남 <br>\n",
    "    : '+'는 에러가 늘어나는 값이므로 net.W 값을 줄여줘야하고 '-'는 에러가 줄어드는 값이므로 net.W 값을 늘려줘야 함\n",
    "* 교재 135쪽 참조\n",
    "\n",
    "아래와 같은 방식으로 W를 갱신할 수 있음 <br>\n",
    "&emsp;&emsp; net.W = net.W - 0.01 * dW <br>\n",
    "* 0.01 = learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet2:\n",
    "    def __init__(self):\n",
    "        np.random.seed(0) #항상 동일한 랜덤값 출력을 위함 (수업 목적)\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        f = lambda w: net.loss(x, t)\n",
    "        dW = numerical_gradient(f, net.W) # 6 방향의 기울기\n",
    "        \n",
    "        return dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = simpleNet2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t # 정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.07523529,  1.92089652, -0.2923073 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03146273,  0.02741463, -0.05887736],\n",
       "       [ 0.0471941 ,  0.04112195, -0.08831604]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.gradient(x,t) # 입력과 정답을 넣어주면 그 때의 기울기가 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyperparameters (최적화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = 0.1\n",
    "learning_rate = 0.5\n",
    "steps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the network !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.W # train 전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6674507891066104"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(steps):\\n    grad = net2.gradient(x,t)\\n    print(i,grad)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in range(steps):\n",
    "    grad = net2.gradient(x,t)\n",
    "    print(i,grad)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "vloss = np.zeros((steps, 1))\n",
    "\n",
    "# training \n",
    "for i in range(steps):\n",
    "    grad = net2.gradient(x, t) # 기울기\n",
    "    net2.W = net2.W - learning_rate * grad\n",
    "    \n",
    "    loss_i = net2.loss(x, t)\n",
    "    vloss[i] = loss_i\n",
    "    #print(i, grad)\n",
    "    \n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19091584, -0.97057437,  3.92260607],\n",
       "       [-0.11881157, -0.18853937,  3.43852425]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.W # train 후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006345425054545023"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'lr = 0.5')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vloss)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('loss')\n",
    "plt.title('lr = {}'.format(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction / Infererence (추론과정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00761909, -0.75203006,  5.44823547])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00430938, 0.00201606, 0.99367456])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(net2.predict(x)) #확률로 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(net2.predict(x))) #추론한 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(t) #정답 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(net2.predict(x))) == np.argmax(t) # 두 개가 같은지 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
