{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a-c)   #개선\n",
    "    sum_exp_a = sum(np.exp(a-c))\n",
    "    y = exp_a/sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 ONE-HOT 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        np.random.seed(5) #항상 동일한 랜덤값 출력을 위함 (수업 목적)\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화 (정규분포 : 평균이 0이고 표준편차가 1인 분포값)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t): #입력을 받아서 정답과 얼마나 차이가 나는지 보기(error)\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2X3형태의 형상을 갖는 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/NN.png' width=200px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = simpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.6, 0.9]) # 입력\n",
    "t = np.array([0, 0, 1]) #정답, TARGET, 정답의 확률(3개 더했을 때 총 합이 1이 나와야 함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2개의 입력값($x_1$, $x_2$)과 3개의 정답($y_1$, $y_2$, $y_3$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44122749, -0.33087015,  2.43077119],\n",
       "       [-0.25209213,  0.10960984,  1.58248112]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W #어떤값으로 초기화 되어있는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력값을 이용하여 FORWARD 방향 연산해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03785358 -0.09987323  2.88269572]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = softmax(pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05243789 0.04569106 0.90187105]\n"
     ]
    }
   ],
   "source": [
    "print(y) # 확률로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y) # y중에 값을 가장 크게 하는 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(t) # 정답"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동일한 입력값과 정답을 이용하여 loss 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10328361502771058"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.loss(x,t) # 입력 x를 넣고, target인 t를 넣으면 loss는 0.1이 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greadient 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient_single_point(f, x, verbose=False): \n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    if verbose:\n",
    "        print('x.size={}'.format(x.size)) # (x0, x1) 을 입력으로 받음 --> 2\n",
    "       \n",
    "    for idx in range(x.size): #축별로 계산\n",
    "        v_keep = x[idx]\n",
    "        \n",
    "        # f(x+h) 계산\n",
    "        x[idx] = float(v_keep) + h #n차원 입력 중 해당 차원으로만 h를 더하고\n",
    "        fxh1 = f(x)\n",
    "        if verbose:\n",
    "            print(x, '-->', fxh1)\n",
    "        \n",
    "        # f(x-h) 계산\n",
    "        x[idx] = float(v_keep) - h #n차원 입력 중 해당 차원으로만 h를 빼서\n",
    "        fxh2 = f(x)\n",
    "        if verbose:\n",
    "            print(x, '-->', fxh2)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h) #n차원 방향의 차분을 구함 !\n",
    "        x[idx] = v_keep # 값 복원\n",
    "        \n",
    "        if verbose:\n",
    "            print('grad[{}]={}'.format(idx, grad[idx]))\n",
    "            print()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, X):\n",
    "    if X.ndim == 1:\n",
    "        return numerical_gradient_single_point(f, X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        \n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = numerical_gradient_single_point(f, x)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44122749, -0.33087015,  2.43077119],\n",
       "       [-0.25209213,  0.10960984,  1.58248112]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고) lambda <br>\n",
    "&emsp;&emsp;lambda 인자리스트: 표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w): #Loss 산의 높이\n",
    "    return net.loss(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위처럼 해도 되지만, 아래처럼 lambda 를 써서 간단히 하는 것도 좋은 방법. 단, 인자로 들어가는 w는 dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda w: net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW = numerical_gradient(f, net.W) # 6 방향의 기울기 (6개의 방향의 기울기를 구할 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03146273  0.02741463 -0.05887736]\n",
      " [ 0.0471941   0.04112195 -0.08831604]]\n"
     ]
    }
   ],
   "source": [
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44122749, -0.33087015,  2.43077119],\n",
       "       [-0.25209213,  0.10960984,  1.58248112]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생각해보기\n",
    "* 각 숫자들의 의미를 생각해보세요 (2020/11/24일 수업) <br>\n",
    "    : net.W에서 하나의 값을 변동시키면 loss(에러)가 dW값 만큼 줄어든다. <br>\n",
    "    : 예를 들어 net.W의 (1,1)에 있는 0.44의 값을 변동시키면 loss는 dW에서 net.W와 같은 위치에 있는 값인 0.03배만큼 늘어남 <br>\n",
    "    : '+'는 에러가 늘어나는 값이므로 net.W 값을 줄여줘야하고 '-'는 에러가 줄어드는 값이므로 net.W 값을 늘려줘야 함\n",
    "* 교재 135쪽 참조\n",
    "\n",
    "아래와 같은 방식으로 W를 갱신할 수 있음 <br>\n",
    "&emsp;&emsp; net.W = net.W - 0.01 * dW <br>\n",
    "* 0.01 = learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet2:\n",
    "    def __init__(self):\n",
    "        np.random.seed(0) #항상 동일한 랜덤값 출력을 위함 (수업 목적)\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        f = lambda w: net.loss(x, t)\n",
    "        dW = numerical_gradient(f, net.W) # 6 방향의 기울기\n",
    "        \n",
    "        return dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = simpleNet2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t # 정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.07523529,  1.92089652, -0.2923073 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03146273,  0.02741463, -0.05887736],\n",
       "       [ 0.0471941 ,  0.04112195, -0.08831604]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.gradient(x,t) # 입력과 정답을 넣어주면 그 때의 기울기가 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyperparameters (최적화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = 0.1\n",
    "learning_rate = 0.5\n",
    "steps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the network !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19091584, -0.97057437,  3.92260607],\n",
       "       [-0.11881157, -0.18853937,  3.43852425]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.W # train 전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006345425054545247"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(steps):\\n    grad = net2.gradient(x,t)\\n    print(i,grad)\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in range(steps):\n",
    "    grad = net2.gradient(x,t)\n",
    "    print(i,grad)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "vloss = np.zeros((steps, 1))\n",
    "\n",
    "# training \n",
    "for i in range(steps):\n",
    "    grad = net2.gradient(x, t) # 기울기\n",
    "    net2.W = net2.W - learning_rate * grad\n",
    "    \n",
    "    loss_i = net2.loss(x, t)\n",
    "    vloss[i] = loss_i\n",
    "    #print(i, grad)\n",
    "    \n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.38222067, -2.34130594,  6.86647415],\n",
       "       [-2.47851633, -2.24463674,  7.85432638]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.W # train 후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.985156233225356e-07"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'lr = 0.5')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vloss)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('loss')\n",
    "plt.title('lr = {}'.format(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction / Infererence (추론과정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.0599971 , -3.42495663, 11.18877823])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.48388076e-07, 4.50127048e-07, 9.99998901e-01])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(net2.predict(x)) #확률로 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(net2.predict(x))) #추론한 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(t) #정답 클래스"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
